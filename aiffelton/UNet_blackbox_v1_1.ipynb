{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8313cb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244e8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_pre_TS_damage_part : 32993\n",
      "file_list_pre_TS_damage : 50759\n",
      "file_list_pre_TL_damage_part : 32994\n",
      "file_list_pre_TL_damage : 50760\n",
      "견적서 파일 개수 : 24012\n"
     ]
    }
   ],
   "source": [
    "#전처리 된 파일리스트 변수 선언 코드\n",
    "\n",
    "dir_path_pre_TS_damage_part = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage_part'\n",
    "file_list_pre_TS_damage_part = os.listdir(dir_path_pre_TS_damage_part)\n",
    "print(\"file_list_pre_TS_damage_part :\",len(file_list_pre_TS_damage_part))\n",
    "\n",
    "dir_path_pre_TS_damage = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage'\n",
    "file_list_pre_TS_damage = os.listdir(dir_path_pre_TS_damage)\n",
    "print(\"file_list_pre_TS_damage :\",len(file_list_pre_TS_damage))\n",
    "\n",
    "dir_path_pre_TL_damage_part = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage_part'\n",
    "file_list_pre_TL_damage_part = os.listdir(dir_path_pre_TL_damage_part)\n",
    "print(\"file_list_pre_TL_damage_part :\",len(file_list_pre_TL_damage_part))\n",
    "\n",
    "dir_path_pre_TL_damage = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage'\n",
    "file_list_pre_TL_damage = os.listdir(dir_path_pre_TL_damage)\n",
    "print(\"file_list_pre_TL_damage :\",len(file_list_pre_TL_damage))\n",
    "\n",
    "dir_path_pre_견적서 = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/견적서'\n",
    "file_list_pre_견적서 = os.listdir(dir_path_pre_견적서)\n",
    "print(\"견적서 파일 개수 :\",len(file_list_pre_견적서))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83b063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_pre_TS_damage_part_demo : 8000\n",
      "file_list_pre_TS_damage_part_demo : 8000\n"
     ]
    }
   ],
   "source": [
    "dir_path_pre_TS_damage_part_demo = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage_part_demo'\n",
    "file_list_pre_TS_damage_part_demo = os.listdir(dir_path_pre_TS_damage_part_demo)\n",
    "print(\"file_list_pre_TS_damage_part_demo :\",len(file_list_pre_TS_damage_part_demo))\n",
    "\n",
    "dir_path_pre_TL_damage_part_demo = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage_part_demo'\n",
    "file_list_pre_TL_damage_part_demo = os.listdir(dir_path_pre_TL_damage_part_demo)\n",
    "print(\"file_list_pre_TS_damage_part_demo :\",len(file_list_pre_TL_damage_part_demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fb04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_pre_TS_damage_part_val : 2000\n",
      "file_list_pre_TL_damage_part_val : 2000\n"
     ]
    }
   ],
   "source": [
    "dir_path_pre_TS_damage_part_val = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage_part_val'\n",
    "file_list_pre_TS_damage_part_val = os.listdir(dir_path_pre_TS_damage_part_val)\n",
    "\n",
    "dir_path_pre_TL_damage_part_val = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage_part_val'\n",
    "file_list_pre_TL_damage_part_val = os.listdir(dir_path_pre_TL_damage_part_val)\n",
    "\n",
    "print(\"file_list_pre_TS_damage_part_val :\",len(file_list_pre_TS_damage_part_val))\n",
    "print(\"file_list_pre_TL_damage_part_val :\",len(file_list_pre_TL_damage_part_val))\n",
    "# # 결과 출력하기\n",
    "# print(random_files_TS_damage_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588389aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eed8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_training(path):\n",
    "                                                         \n",
    "    def make_image_dataset(img_name):\n",
    "        image_path = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage_part_demo/' + img_name +'.jpg'\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((256, 256)) #input에 맞게 나중에 수정할 것\n",
    "        image = np.array(image)\n",
    "        image = image / 255.0  # 정규화 추가\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_segmentation_map_dataset(json_file):\n",
    "        json_path = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage_part_demo/' + json_file + '.json'\n",
    "        with open(json_path, 'r', encoding='UTF-8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "\n",
    "        img = np.zeros((json_data['images']['height'], json_data['images']['width']), np.uint8)\n",
    "\n",
    "        for ann in json_data['annotations']:\n",
    "            if 'segmentation' in ann:\n",
    "                segmentation = ann['segmentation'][0][0]\n",
    "                cv2.fillPoly(img, [np.array(segmentation)], (255, 255, 255)) #흰색\n",
    "                \n",
    "        img = cv2.resize(img, (256,256,)) #input에 맞게 나중에 수정할 것\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)  # 마지막 차원 추가\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def generator():\n",
    "        for filename in os.listdir(path):\n",
    "            final_img = make_image_dataset(filename.split('.')[0])\n",
    "            final_map = make_segmentation_map_dataset(filename.split('.')[0])\n",
    "            yield (final_img, final_map)\n",
    "    \n",
    "        \n",
    "    \n",
    "    dataset =  tf.data.Dataset.from_generator(generator,\n",
    "                                              (tf.float64, tf.float64))\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "#     result = dataset.__iter__()\n",
    "#     return result\n",
    "    return dataset\n",
    "# tf.data.Dataset 객체를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d735a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_TS_damage_part_demo = get_data_training(dir_path_pre_TS_damage_part_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ee5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10))\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "    \n",
    "#     ax.imshow(final_map_demo[i].numpy().astype(int))\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180d5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_val(path):\n",
    "                                                         \n",
    "    def make_image_dataset(img_name):\n",
    "        image_path = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/원천데이터/TS_damage_part_val/' + img_name +'.jpg'\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((256, 256)) #input에 맞게 나중에 수정할 것\n",
    "        image = np.array(image)\n",
    "        image = image / 255.0  # 정규화 추가\n",
    "        return image\n",
    "    \n",
    "    def make_segmentation_map_dataset(json_file):\n",
    "        json_path = os.getenv('HOME')+'/aiffel/blackbox/preprocessed_training/라벨링데이터/TL_damage_part_val/' + json_file + '.json'\n",
    "        with open(json_path, 'r', encoding='UTF-8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "\n",
    "        img = np.zeros((json_data['images']['height'], json_data['images']['width'], ), np.uint8)\n",
    "\n",
    "        for ann in json_data['annotations']:\n",
    "            if 'segmentation' in ann:\n",
    "                segmentation = ann['segmentation'][0][0]\n",
    "                cv2.fillPoly(img, [np.array(segmentation)], (255, 255, 255)) #흰색\n",
    "        img = cv2.resize(img, (256,256,)) #input에 맞게 나중에 수정할 것\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)  # 마지막 차원 추가\n",
    "        return img\n",
    "    \n",
    "    def generator():\n",
    "        for filename in os.listdir(path):\n",
    "            final_img = make_image_dataset(filename.split('.')[0])\n",
    "            final_map = make_segmentation_map_dataset(filename.split('.')[0])\n",
    "            yield (final_img, final_map)\n",
    "    \n",
    "        \n",
    "    \n",
    "    dataset =  tf.data.Dataset.from_generator(generator,\n",
    "                                              (tf.float64, tf.float64))\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "#     result = dataset.__iter__()\n",
    "#     return result\n",
    "    return dataset\n",
    "# tf.data.Dataset 객체를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7b265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_TS_damage_part_val = get_data_val(dir_path_pre_TS_damage_part_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9788ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets_TS_damage_part_demo\n",
    "test_dataset = datasets_TS_damage_part_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40a42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "   # Conv2D then ReLU activation\n",
    "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5416c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   p = layers.Dropout(0.3)(p)\n",
    "\n",
    "   return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fae8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "   # upsample\n",
    "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "   # concatenate\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   # dropout\n",
    "   x = layers.Dropout(0.3)(x)\n",
    "   # Conv2D twice with ReLU activation\n",
    "   x = double_conv_block(x, n_filters)\n",
    "\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1020d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model():\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(256,256,3))\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444ea3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = build_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f25628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "METRICS = [tf.keras.metrics.BinaryAccuracy()]\n",
    "\n",
    "unet_model.compile(optimizer='adam',\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=METRICS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5dd598",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6f2d5",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "     58/Unknown - 178s 3s/step - loss: 0.5399 - binary_accuracy: 0.7896"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 6\n",
    "\n",
    "# 체크포인트 저장 경로 및 파일 이름 지정\n",
    "checkpoint_path = os.path.join(os.getenv('HOME'), 'aiffel/blackbox/checkpoints', 'cp-{epoch:04d}.ckpt')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 체크포인트 콜백 정의\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True, \n",
    "    save_freq=2 # 2 에포크마다 체크포인트 저장\n",
    ")\n",
    "\n",
    "history = unet_model.fit(\n",
    "    train_dataset, \n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[cp_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d7d42",
   "metadata": {},
   "source": [
    "### 모델학습 (이전코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, masks in test_dataset.take(2):\n",
    "#     sample_image, sample_mask = images[1], masks[1]\n",
    "#     sample_mask = tf.reshape(sample_mask, shape=(256, 256, 1))\n",
    "#     display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display(display_list):\n",
    "#   plt.figure(figsize=(15, 15))\n",
    "\n",
    "#   title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "#   for i in range(len(display_list)):\n",
    "#     plt.subplot(1, len(display_list), i+1)\n",
    "#     plt.title(title[i])\n",
    "#     plt.imshow(tf.keras.utils.array_to_img(display_list[i], data_format='channels_last'))\n",
    "#     plt.axis('off')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for final_img_demo, final_map_demo in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([final_img[0], final_map[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
    "        print(model.predict(sample_image[tf.newaxis, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520b62e",
   "metadata": {},
   "source": [
    "아하 마스크가 안나오면 다시 255를 곱하면 될수도."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b189019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  # 이미지 출력에 대한 설정\n",
    "  plt.figure(figsize=(15, 15))\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "  # display_list의 각 이미지를 출력\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i], data_format='channels_last'))\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "  # 예측 결과 중 가장 높은 값의 인덱스로부터 마스크 생성\n",
    "  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        # 데이터셋으로부터 이미지와 마스크를 가져와서 예측 결과 시각화\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        # 샘플 이미지와 마스크를 이용하여 예측 결과 시각화\n",
    "        display([sample_image, sample_mask,\n",
    "                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋으로부터 예측 결과 시각화\n",
    "show_predictions(dataset=datasets_TS_damage_part_demo, num=1)\n",
    "\n",
    "# 샘플 이미지로부터 예측 결과 시각화\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620149ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
