{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87be2233",
   "metadata": {},
   "source": [
    "# [GD-09] 프로젝트: 뉴스기사 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ee73e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b804e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import os\n",
    "import tensorflow\n",
    "import summa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844dde09",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ff308",
   "metadata": {},
   "source": [
    "사용할 뉴스기사 데이터 \\\n",
    "https://github.com/sunnysai12345/News_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406069f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5118e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/news_summary_more.csv\", nrows=50000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤한 10개 샘플 출력\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876dc3bd",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e90804",
   "metadata": {},
   "source": [
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. \\\n",
    "만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28198c1",
   "metadata": {},
   "source": [
    "#### 중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5791f83",
   "metadata": {},
   "source": [
    "데이터의 중복 샘플 유무를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae31ebd",
   "metadata": {},
   "source": [
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['headlines'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c82497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b1ecdf",
   "metadata": {},
   "source": [
    "#### 텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed130d2",
   "metadata": {},
   "source": [
    "같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우\\\n",
    "예를 들어서 it'll은 it will과 같고, mustn't과 must not은 사실 같은 표현\\\n",
    "기계 학습 전에 미리 같은 표현으로 통일 > 기계의 연산량을 줄일 수 있는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10e715",
   "metadata": {},
   "source": [
    "* 텍스트 정규화 사전\\\n",
    "https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb35e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7306e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a24a0f51",
   "metadata": {},
   "source": [
    "불용어(stopwords) - 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재\\\n",
    "NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b84d3",
   "metadata": {},
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e81805cd",
   "metadata": {},
   "source": [
    "전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2278bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf040c5",
   "metadata": {},
   "source": [
    "함수가 잘 작동하는 것을 확인\\\n",
    "훈련 데이터 전체에 대해서 전처리를 수행\\\n",
    "text의 경우에는 불용어를 제거, headlines의 경우에는 불용어를 제거하지 않을 것 - 따로 호출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d5dde",
   "metadata": {},
   "source": [
    "headlines에 대해서 전처리 함수를 호출해 줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headlines = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7d9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f933009e",
   "metadata": {},
   "source": [
    "텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋다. \\\n",
    "정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있다. \\\n",
    "이렇게 되면 샘플 자체가 빈 값을 가지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13916c78",
   "metadata": {},
   "source": [
    "데이터들을 데이터프레임에 재저장\\\n",
    "빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65319c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b16d4",
   "metadata": {},
   "source": [
    "이전과 같이 .isnull().sum()을 사용해서 Null 값이 생겼는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90671a0",
   "metadata": {},
   "source": [
    "### 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c3681",
   "metadata": {},
   "source": [
    "* 필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례\n",
    "* Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87d7e3",
   "metadata": {},
   "source": [
    "text의 경우 최소 길이가 1, 최대 길이가 60의 차이를 보인다.\\\n",
    "평균 길이는 35로 대체적으로 25~45 사이의 길이를 가진다.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbb8d4",
   "metadata": {},
   "source": [
    "headlines의 경우 최소 길이가 1, 최대 길이가 19, 그리고 평균 길이가 9로 \\\n",
    "text에 비해 상대적으로 길이가 짧다. \\\n",
    "대체적으로 10언저리 길이를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973885e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ee712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "956249ea",
   "metadata": {},
   "source": [
    "text의 최대 길이와 headlines의 적절한 최대 길이를 임의로 정해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 30\n",
    "headlines_max_len = 10\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d681549",
   "metadata": {},
   "source": [
    "각각 30과 10으로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 \\\n",
    "포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는 데 도움이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31aceb0",
   "metadata": {},
   "source": [
    "훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df42477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23a695",
   "metadata": {},
   "source": [
    "text와 headlines에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 있겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790217cf",
   "metadata": {},
   "source": [
    "각각 30과 10으로 패딩을 하게 되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, \\\n",
    "text 열의 경우에는 약 11%의 샘플들이 내용이 망가지게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a3f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32410a63",
   "metadata": {},
   "source": [
    "정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43209e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15423ded",
   "metadata": {},
   "source": [
    "#### 시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56436027",
   "metadata": {},
   "source": [
    "디코더는 시작 토큰을 입력받아 문장을 생성하기 시작,\n",
    "종료 토큰을 예측한 순간에 문장 생성을 멈춘다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "340ffebd",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55857e",
   "metadata": {},
   "source": [
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f41aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7fa59",
   "metadata": {},
   "source": [
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67640560",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ae8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ced5502d",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터를 분리 - encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66704c",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb9bb56",
   "metadata": {},
   "source": [
    "섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리\\\n",
    "전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944578e7",
   "metadata": {},
   "source": [
    "#### 단어 집합(vocabulary) 만들기 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2130281",
   "metadata": {},
   "source": [
    "기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 함.\\\n",
    "각 단어에 고유한 정수를 맵핑하는 작업이 필요\\\n",
    "이 과정을 단어 집합(vocabulary) 을 만든다고 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7fc5d",
   "metadata": {},
   "source": [
    "현재 생성된 단어 집합은 src_tokenizer.word_index에 저장\\\n",
    "우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, \\\n",
    "빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740e682",
   "metadata": {},
   "source": [
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, \\\n",
    "이를 통해서 통계적인 정보를 얻을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6296cf",
   "metadata": {},
   "source": [
    "정상적으로 정수 인코딩 작업이 끝났어요.\\\n",
    "현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 넘는 숫자들은 존재하지 않음. \\\n",
    "그런데 다음 작업인 패딩 하기로 넘어가기 전에 한 가지 점검해야 할 것이 있어요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8f98d",
   "metadata": {},
   "source": [
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 \\\n",
    "이제 빈(empty) 샘플이 되었을 가능성이 있다. \\\n",
    "이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, \\\n",
    "애초에 평균 길이가 짧은 headlines의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0aff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df8cf841",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장\\\n",
    "이 샘플들은 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa201eb",
   "metadata": {},
   "source": [
    "#### 패딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e5926",
   "metadata": {},
   "source": [
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 한다.\\\n",
    "최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3389f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae9d0c",
   "metadata": {},
   "source": [
    "이제 학습에 필요한 데이터 전처리가 모두 끝났다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050aec8",
   "metadata": {},
   "source": [
    "### 모델 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3670e48",
   "metadata": {},
   "source": [
    "#### 우선 함수형 API를 이용해서 인코더를 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becf16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "# encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "# encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e155e",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256\\\n",
    "hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터.\n",
    "\n",
    "인코더의 LSTM에서 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있다.\n",
    "\n",
    "LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용할 수 있다. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여\\\n",
    "모델의 과적합(overfitting)을 해결해주는 방법이다.\n",
    "\n",
    "recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이다. time step의 입력을 랜덤으로 생략해 준다.\n",
    "* recurrent dropout을 사용할 시 cuDNN을 사용할 수 없어서 recurrent dropout을 사용하지 않을 때보다 학습 시간이 오래 걸린다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d37d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6acbe4c",
   "metadata": {},
   "source": [
    "디코더를 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78197604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b56935",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일\\\n",
    "하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080530bd",
   "metadata": {},
   "source": [
    "디코더의 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f49fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b808b7",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 headlines의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 함. \\\n",
    "그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496507d",
   "metadata": {},
   "source": [
    "디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있어요! 바로 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b19bf5",
   "metadata": {},
   "source": [
    "### Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94e458",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffda41",
   "metadata": {},
   "source": [
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. \\\n",
    "실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21560355",
   "metadata": {},
   "source": [
    "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, \\\n",
    "어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a1ffc",
   "metadata": {},
   "source": [
    "###  모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ba416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c11eb",
   "metadata": {},
   "source": [
    "'조기 종료'를 뜻하는 EarlyStopping은 특정 조건이 충족되면 훈련을 멈추는 역할을 한다.\\\n",
    "위 코드에서는 val_loss(검증 데이터의 손실)을 관찰하다가, \\\n",
    "검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정돼 있다. \\\n",
    "EarlyStopping이 작동한다면 epochs가 아무리 크게 설정되어 있어도 모델 훈련을 최적점에서 멈출 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6132f2f",
   "metadata": {},
   "source": [
    "### 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3e61a",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf72444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fba9c2",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dccfb3",
   "metadata": {},
   "source": [
    "### Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8991061",
   "metadata": {},
   "source": [
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97765453",
   "metadata": {},
   "source": [
    "### 모델 테스트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b728ea",
   "metadata": {},
   "source": [
    "주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e7008",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58d61e",
   "metadata": {},
   "source": [
    "많은 결과가 출력이 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보임.\\\n",
    "\n",
    "\n",
    "성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법\\\n",
    "빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), \\\n",
    "또는 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0516e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33a1f52",
   "metadata": {},
   "source": [
    "### Step 5. Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed037b5",
   "metadata": {},
   "source": [
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee76b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee929b70",
   "metadata": {},
   "source": [
    "Python에서 CSV 파일을 TXT로 변환하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1436ae2",
   "metadata": {},
   "source": [
    "* Workbook 클래스를 사용하여 CSV 파일을 로드합니다.\n",
    "* Workbook.save() 메서드를 사용하여 CSV를 TXT로 변환합니다.\n",
    "\n",
    "https://blog.aspose.com/ko/cells/convert-csv-to-txt-in-python/#Python-Library-for-CSV-to-TXT-Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee20add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import  jpype     \n",
    "import  asposecells     \n",
    "jpype.startJVM() \n",
    "from asposecells.api import Workbook\n",
    "\n",
    "print(\"=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/news_summary_more.csv\", nrows=50000)\n",
    "# print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8f0fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=33\n"
     ]
    }
   ],
   "source": [
    "# load CSV file\n",
    "workbook = Workbook(os.getenv(\"HOME\")+\"/aiffel/news_summarization/news_summary_more.csv\");\n",
    "\n",
    "# save as TXT\n",
    "workbook.save(os.getenv(\"HOME\")+\"/aiffel/news_summarization/news_summary_more.txt\");\n",
    "\n",
    "print(\"=33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/aiffel/aiffel/news_summarization/news_summary_more.txt\", \"r\") as f:\n",
    "    text = f.read().splitlines()\n",
    "\n",
    "print(\"=333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b14035",
   "metadata": {},
   "source": [
    "* Python txt 파일 읽기 \\\n",
    "https://jimmy-ai.tistory.com/232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6dd5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines\ttext\n",
      "upGrad learner switches to career in ML & Al with 90% salary hike\tSaurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Delhi techie wins free food from Swiggy for one year on CRED\tKunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "New Zealand end Rohit Sharma-led India's 12-match winning streak\tNew Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "Aegon life iTerm insurance plan helps customers save tax\tWith Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7b071",
   "metadata": {},
   "source": [
    "### summarize 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ab3e9",
   "metadata": {},
   "source": [
    "text (str) : 요약할 테스트.\\\n",
    "ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값\\\n",
    "words (int or None, optional) – 출력에 포함할 단어 수.\\\n",
    "만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.\\\n",
    "split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458cc48",
   "metadata": {},
   "source": [
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행\\\n",
    "그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있다.\\\n",
    "비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여봄.\\\n",
    "원문의 0.005%만을 출력하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c57cd9",
   "metadata": {},
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82719827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b796823",
   "metadata": {},
   "source": [
    "단어의 수로 요약문의 크기를 조절할 수도 있어요. \\\n",
    "단어를 50개만 선택하도록 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6b748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd2a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eddbf44",
   "metadata": {},
   "source": [
    "### 프로젝트 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dade94",
   "metadata": {},
   "source": [
    "RNN 모델과 LSTM 모델에 대한 이해가 다소 어려웠다.\\\n",
    "sunnma summarize 사용을 위해 csv파일을 txt파일로 바꾸어 시도해보았으나 summary 과정에서 실행이 잘 되지 않았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fbe33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
